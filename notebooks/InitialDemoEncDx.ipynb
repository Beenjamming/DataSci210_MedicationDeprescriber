{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas\n",
    "#%pip install numpy\n",
    "#%pip install langchain\n",
    "#%pip install langchain-community\n",
    "#%pip install langchain-groq\n",
    "#%pip install sentence-transformers\n",
    "#%pip install -U langchain-community faiss-cpu langchain-openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "import os \n",
    "import json\n",
    "\n",
    "#define groq key \n",
    "groq_key = os.environ['groqkey']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model variables\n",
    "llama_70 = 'llama3-70b-8192'\n",
    "llama_31 = 'llama-3.1-70b-versatile'\n",
    "mixtral = \"mixtral-8x7b-32768\"\n",
    "gemma_2 = 'gemma2-9b-it'\n",
    "llama_tool_70 = 'llama3-groq-70b-8192-tool-use-preview'\n",
    "\n",
    "gemma = ChatGroq(\n",
    "    temperature=0,\n",
    "    model=gemma_2,\n",
    "    api_key=groq_key \n",
    ")\n",
    "\n",
    "mixtral = ChatGroq(\n",
    "    temperature=0,\n",
    "    model=mixtral,\n",
    "    api_key=groq_key \n",
    ")\n",
    "\n",
    "llama3 = ChatGroq(\n",
    "    temperature=0,\n",
    "    model=llama_70,\n",
    "    api_key=groq_key \n",
    ")\n",
    "\n",
    "llama_tool = ChatGroq(\n",
    "    temperature=0,\n",
    "    model=llama_70,\n",
    "    api_key=groq_key \n",
    ")\n",
    "\n",
    "llama_3_1 = ChatGroq(\n",
    "    temperature=0,\n",
    "    model=llama_31,\n",
    "    api_key=groq_key \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"When considering PPI (Proton Pump Inhibitor) deprescribing for a patient at discharge, several factors should be evaluated to ensure safe and effective discontinuation. Here are the key considerations:\\n\\n1. **Indication for PPI use**: Review the original reason for starting the PPI. If the indication was for a short-term condition, such as gastroesophageal reflux disease (GERD) or peptic ulcer disease, and the condition has resolved, deprescribing may be appropriate.\\n2. **Duration of PPI use**: Assess the length of time the patient has been taking the PPI. Long-term use (more than 8-12 weeks) increases the risk of rebound acid hypersecretion and may make deprescribing more challenging.\\n3. **Dose and frequency**: Evaluate the current PPI dose and frequency. Patients on higher doses or more frequent dosing may require a more gradual taper to minimize rebound symptoms.\\n4. **Symptom control**: Assess the patient's current symptoms and whether they are well-controlled on the PPI. If symptoms are not well-controlled, deprescribing may not be the best option.\\n5. **Risk of rebound acid hypersecretion**: Consider the patient's risk of developing rebound acid hypersecretion, a condition characterized by increased acid production after PPI discontinuation. Factors that increase this risk include:\\n\\t* Long-term PPI use\\n\\t* High-dose PPI use\\n\\t* History of peptic ulcer disease or GERD\\n\\t* Presence of Helicobacter pylori infection\\n6. **Alternative treatments**: Evaluate the need for alternative treatments, such as histamine-2 (H2) blockers or antacids, to manage symptoms during the deprescribing process.\\n7. **Patient education and monitoring**: Educate the patient on the risks and benefits of PPI deprescribing, and ensure they understand the importance of monitoring their symptoms and reporting any changes.\\n8. **Gradual tapering**: Develop a plan for gradual tapering of the PPI dose and frequency to minimize rebound symptoms. A common tapering schedule is to reduce the dose by 50% every 1-2 weeks until the patient is off the PPI.\\n9. **Follow-up**: Schedule follow-up appointments to monitor the patient's symptoms and adjust the deprescribing plan as needed.\\n\\nBy carefully evaluating these factors, you can develop a safe and effective PPI deprescribing plan for your patient at discharge.\", response_metadata={'token_usage': {'completion_tokens': 503, 'prompt_tokens': 65, 'total_tokens': 568, 'completion_time': 2.012, 'prompt_time': 0.024795235, 'queue_time': 0.021042874000000003, 'total_time': 2.036795235}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'stop', 'logprobs': None}, id='run-e59654b0-7653-4eec-a482-030c5e32d129-0', usage_metadata={'input_tokens': 65, 'output_tokens': 503, 'total_tokens': 568})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = \"You are a knowledgeable medical provider who specializes in medication management.\"\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "chain = prompt | llama_3_1\n",
    "chain.invoke({\"text\": \"Explain what should be evaluated for PPI deprescribing for a patient at discharge.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_9396\\1026861699.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  base_embeddings = HuggingFaceEmbeddings(model_name=\"NeuML/pubmedbert-base-embeddings\")\n",
      "f:\\LangChain\\.venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "base_embeddings = HuggingFaceEmbeddings(model_name=\"NeuML/pubmedbert-base-embeddings\")\n",
    "text_splitter = RecursiveCharacterTextSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"F:/LangChain/data/\"\n",
    "noteConcepts = pd.read_csv(base_path + 'noteConcepts.txt', sep=\"|\")\n",
    "encounters = pd.read_csv(base_path + 'encounters.txt', sep=\"|\")\n",
    "orders = pd.read_csv(base_path + 'orders.txt', sep=\"|\")\n",
    "hospitalAcquiredDx = pd.read_csv(base_path + 'hospitalAcquiredDx.txt', sep=\"|\")\n",
    "noteText = pd.read_csv(base_path + 'noteText.txt', sep=\"|\")\n",
    "presentOnAdmitDx = pd.read_csv(base_path + 'presentOnAdmitDx.txt', sep=\"|\")\n",
    "#select random EncounterKey\n",
    "encounterKey = encounters.sample(1)['EncounterKey'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter all dfs to the selected EncounterKey\n",
    "noteConcepts = noteConcepts[noteConcepts['EncounterKey'] == encounterKey]\n",
    "orders = orders[orders['EncounterKey'] == encounterKey]\n",
    "hospitalAcquiredDx = hospitalAcquiredDx[hospitalAcquiredDx['EncounterKey'] == encounterKey]\n",
    "noteText = noteText[noteText['EncounterKey'] == encounterKey]\n",
    "presentOnAdmitDx = presentOnAdmitDx[presentOnAdmitDx['EncounterKey'] == encounterKey]\n",
    "encounters = encounters[encounters['EncounterKey'] == encounterKey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"EncounterKey\":\"D5572323A153F5\",\"PatientKey\":\"D6A6FA9D7F0784\",\"Sex\":\"Female\",\"Age_y\":11,\"BirthDate\":\"2012-04-27\",\"PtAdmitDate\":\"2023-08-02\",\"PtDischargeDate\":\"2023-09-04\",\"DRG\":\"MAJOR PANCREAS, LIVER AND SHUNT PROCEDURES\",\"FinancialClass\":\"Medi-Cal Standard\",\"AdmissionOrigin\":\"Direct Admission\",\"AdmissionSource\":\"Physician Referral\",\"AdmissionType\":\"Routine\\/Elective\",\"PrimaryDx\":\"Other chronic pancreatitis  (CMS code)\",\"PresentOnAdmissionDiagnosisComboKey\":-1,\"HospitalAcquiredDiagnosisComboKey\":-1,\"DischargeDisposition\":\"Home or Self Care\",\"DischargePatientClass\":\"Inpatient\"}]\n"
     ]
    }
   ],
   "source": [
    "#change encounters to a json object\n",
    "encounters = encounters.to_json(orient=\"records\")\n",
    "print(encounters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_from_content(content):\n",
    "    # Find the JSON part within the content\n",
    "    start_index = content.find('{')\n",
    "    end_index = content.rfind('}') + 1\n",
    "    json_str = content[start_index:end_index]\n",
    "\n",
    "    # Parse the JSON string\n",
    "    parsed_json = json.loads(json_str)\n",
    "    \n",
    "    return parsed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Based on the provided JSON information, here\\'s the answer for each condition:\\n\\n```json\\n{\\n  \"Mild to moderate esophagitis\": false,\\n  \"GERD\": false,\\n  \"Peptic Ulcer Disease\": false,\\n  \"Upper GI symptoms\": false,\\n  \"ICU Stress Ulcer Prophylaxis\": false,\\n  \"Barrett\\'s Esophagus\": false,\\n  \"Chronic NSAID use with bleeding risk\": false,\\n  \"Severe esophagitis\": false,\\n  \"Documented history of bleeding GI ulcer\": false,\\n  \"Reasoning\": \"The provided JSON information does not explicitly mention any of the listed conditions. The primary diagnosis is \\'Other chronic pancreatitis\\', which is related to the pancreas, not the esophagus or stomach. The DRG (Diagnosis-Related Group) is \\'MAJOR PANCREAS, LIVER AND SHUNT PROCEDURES\\', which also suggests that the patient\\'s condition is related to the pancreas and liver, rather than the esophagus or stomach. Therefore, based on the available information, it is not possible to confirm the presence of any of the listed conditions.\"\\n}\\n```\\n\\nNote that the absence of information about a particular condition does not necessarily mean that the patient does not have that condition. It simply means that the provided information does not mention it.' response_metadata={'token_usage': {'completion_tokens': 278, 'prompt_tokens': 394, 'total_tokens': 672, 'completion_time': 1.114972901, 'prompt_time': 0.124312833, 'queue_time': 0.612163364, 'total_time': 1.239285734}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'stop', 'logprobs': None} id='run-5d4f4b3b-e3dd-4bb6-a8c8-ab13f5c087a9-0' usage_metadata={'input_tokens': 394, 'output_tokens': 278, 'total_tokens': 672}\n"
     ]
    }
   ],
   "source": [
    "system = \"You are a knowledgeable medical provider who specializes in medication management.\"\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "chain = prompt | llama_3_1\n",
    "response = chain.invoke({\"text\": f\"\"\"Based on the information from this encounter JSON information: {encounters}, does the patient have any of the following:\n",
    "              1. Mild to moderate esoophagitis\n",
    "              2. GERD \n",
    "              3. Peptic Ulcer Disease\n",
    "              4. Upper GI symptoms\n",
    "              5. ICU Stress Ulcer Prophylaxis\n",
    "              6. Barrett's Esophagus\n",
    "              7. Chronic NSAID use with bleeding risk\n",
    "              8. Severe esophagitis\n",
    "              9. Documented history of bleeding GI ulcer\n",
    "              10. Explain the reasoning for your answer\n",
    "            Return the answer for each of these as a formatted JSON object with the key being the condition and the value being a boolean value for the first 9.  For the final question, return a string with the reasoning for your answer.\"\"\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mild to moderate esophagitis': False,\n",
       " 'GERD': False,\n",
       " 'Peptic Ulcer Disease': False,\n",
       " 'Upper GI symptoms': False,\n",
       " 'ICU Stress Ulcer Prophylaxis': False,\n",
       " \"Barrett's Esophagus\": False,\n",
       " 'Chronic NSAID use with bleeding risk': False,\n",
       " 'Severe esophagitis': False,\n",
       " 'Documented history of bleeding GI ulcer': False,\n",
       " 'Reasoning': \"The provided JSON information does not explicitly mention any of the listed conditions. The primary diagnosis is 'Other chronic pancreatitis', which is related to the pancreas, not the esophagus or stomach. The DRG (Diagnosis-Related Group) is 'MAJOR PANCREAS, LIVER AND SHUNT PROCEDURES', which also suggests that the patient's condition is related to the pancreas and liver, rather than the esophagus or stomach. Therefore, based on the available information, it is not possible to confirm the presence of any of the listed conditions.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_json_from_content(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
